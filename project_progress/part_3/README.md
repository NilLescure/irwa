0: Prerrequisites:

Acces to the internet and collab ( Google ).

1: How to run the code Download the ProjectPart1 notebook and the dataset. For good practices reasons, this dataset is not included in this repository so you MUST have access to Aula global or have it downloaded.

Option 1: Google Collab: Upload the both files to google drive and open the notebook Change our hardcoded path in the variable declaration of docs_path for the one in you drive. then you should change the route inside the to_csv method to your folder in both df

Option 2: Local storage In case you want to have the project in local storage you can also replace the docs_path for the one in you pc, also you should change the route inside the to_csv method to your folder in both df This of course assumes that you have installed some notebook interpreter like anaconda jupiter You might also have to download your missing libraries with pip install -x

After you are done with the options above you should have the files clean_df and processed_df. These are not in the repo as they are too big ( also, not a good practice to have data in the repository). If you have any trouble doing the previous steps, please contact with us as these are essential for the execution of the part3 notebook. If you meet all requirements then you may change the routes in the part 3 code like we did before. Now you can run the cells.
